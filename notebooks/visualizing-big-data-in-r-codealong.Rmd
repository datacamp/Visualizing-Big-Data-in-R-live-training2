---
title: "Visualizing Big Data in R"
author: "Richard Cotton"
output: 
  html_document:
    self_contained: false
    lib_dir: trelliscope
---

# Prelude

Install these additional R packages.

```{r, install_pkgs, echo = FALSE, result = "hide"}
rlib <- "~/lib"
dir.create(rlib)
.libPaths(rlib)
library(remotes)
install_version("hexbin", "1.28.1", lib = rlib, upgrade = "never")
install_version("fst", "0.9.2", lib = rlib, upgrade = "never")
install_version("ggcorrplot", "0.1.3", lib = rlib, upgrade = "never")
install_version("trelliscopejs", "0.2.5", lib = rlib, upgrade = "never")
install_version("plotly", "4.9.2.1", lib = rlib, upgrade = "never")
```

# Chapter 1: Too many points - point size, transparency, transformations

Here, you'll look at the LA home prices dataset to explore ways of reducing overplotting.

## Learning objectives

- Understands that one cause of overplotting in scatter plots is simply that there are too many points.
- Can apply point size adjustments, transparency, and axis scale transformations to reduce overplotting problems.
- Can draw and interpret a hex plot.

## Loading the packages

You need a way to import a CSV file, `tibble` and `ggplot2`.

```{r, load_pkg1, message = FALSE}
# Load tibble, ggplot2, and a CSV reader

```

## Exploring the dataset

The dataset is here. Run this chunk!

```{r, data_file1}
data_file <- "../data/LAhomes.csv"
```

Read in the dataset from `data_file`, assigning the result to `la_homes`. Explore it (using whichever functions you like).

```{r, import}
# Read data_file from CSV


# Explore it

```

- `price` is the sale price of the home, in USD.
- `sqft` is the area of the home in square feet (about 0.1 square meters).

Using `la_homes`, draw a scatter plot of `price` versus `sqft`.

```{r, basic_scatter}
# Using la_homes, plot price vs. sqft with point layer

```

## Changing point size

Notice that points in the plot are heavily overplotted in the bottom left corner.

Redraw the basic scatter plot, changing the point size to `0.5`.

```{r, smaller_points}
# Draw same scatter plot, with size 0.5

```

Redraw the basic scatter plot, changing the point shape to be "pixel points".

```{r, pixel_points}
# Draw same scatter plot, with pixel shape

```

## Using transparency

Redraw the basic scatter plot, changing the transparency level of points to `0.25`. Set a white background by using ggplot2's black and white theme.

```{r, transparency}
# Draw same scatter plot, with transparency 0.25 and black & white theme

```

## Transform the axes

Most of the plots are stuck in the bottom-left corner. Transform the x and y axes to spread points more evenly throughout.

Redraw the basic scatter plot, applying a log10 transformation to the x and y scales.

```{r, loglog}
# Draw same scatter plot, with log-log scales

```

Redraw the scatter plot using all three tricks at once.

- Set the point size to `0.5`.
- Set the point transparency to `0.25`.
- Using log10 transformations for the x and y scales.
- Use the black and white theme.

```{r, all_tricks}
# Draw same scatter plot, with all 3 tricks

```

## Hex plots

Draw a hex plot of `price` versus `sqft`.

```{r, hex}
# Using la_homes, plot price vs. sqft with hex layer

```

Redraw the hex plot, applying log10 transformations to the x and y scales.

```{r, hex_loglog}
# Draw same hex plot, with log-log scales

```

Which statement about the trend is true?

- [ ] Price increases roughly linearly with area.
- [ ] Price increases roughly linearly with log area.
- [ ] Log price increases roughly linearly with area.
- [ ] Log price increases roughly linearly with log area.

Which statement about the overplotting is true?

- [ ] The majority of the houses are found in the region of darkest blues on the hex plot.
- [ ] The majority of the houses are found in the region of lightest blues on the hex plot.
- [ ] The hex plot tells us nothing about where the majority of the houses are found.

# Chapter 2: Aligned values - jittering

Here you'll take another look at overplotting in the LA homes dataset.

## Learning objectives

- Understands that one cause of overplotting in scatter plots is low-precision, integer, or categorical variables taking exactly the same values.
- Can apply jittering, transparency, and scale transformations to solve the problem.

## Loading the packages

You'll need `readr`, `dplyr` and `ggplot2`. Just run this code.

```{r, load_pkg2, message = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
```

## Importing and exploring the data

The dataset is here. Run this chunk!

```{r, data_file2}
data_file <- "../data/LAhomes.csv"
```

Import the LA homes dataset from `data_file`, assigning to `la_homes`.

```{r, import_la_homes2}
# Import data_file

```

- `bed` contains the number of bedrooms in the home.

Take a look at the distinct values in `bed` using `distinct()`.

```{r, beds}
# Look at the distinct values of the bath column

```

Notice that the number of bedrooms is always an integer and sometimes zero.

## Scatter plots of price vs. bedrooms

Using `la_homes`, draw a scatter plot of `price` versus `bed`.

```{r, price_vs_beds}
# Using la_homes, plot price vs. bed with a point layer

```

Draw the same plot again, this time jittering the points along the x-axis.

- Use a maximum jitter distance of `0.4` in the x direction.
- Don't jitter in the y direction.

```{r, jitter_x}
# Draw the previous plot but jitter points with width 0.4

```

Most of the points are near the bottom of the plot.

Draw the same jittered plot again, this time using a log10 transformation on the y-scale.

```{r, log_y}
# Draw the previous plot but use a log y-axis

```

## Scatter plots of bathrooms vs. bedrooms

- `bath` contains the number of bathrooms in the home.

Take a look at the distinct values in `bath` using `distinct()`.

```{r, baths}
# Look at the distinct values of the bath column

```

Notice that the dataset includes half and quarter bathrooms (whatever they are).

Draw a scatter plot of `bath` versus `bed`.

```{r, baths_vs_beds}
# Using la_homes, plot bath vs. bed with a point layer

```

Draw the same plot again, this time jittering the points.

- Use a maximum jitter distance of `0.4` in the x direction.
- Use a maximum jitter distance of `0.05` in the y direction.

```{r, bvb_jittered}
# Using la_homes, plot price vs. bed with a point layer

```

## Filtering and transformation

There are three homes with 10 or more bedrooms. These constitute outliers, and for the purpose of drawing nicer plots, we're going to remove them.

Filter `la_homes` for rows where `bed` is less than to `10`, assigning to `la_homes10`. Count the number of rows you removed to check you've done it correctly.

```{r, filtering}
# Filter for bed less than to 10
la_homes10 <- 

# Calculate the number of outliers you removed

```

Draw the same jittered scatter plot again, this time using the filtered dataset (`la_homes10`). As before, use a jitter width of `0.4` and a jitter height of `0.05`.

```{r, bvb10_jittered}
# Draw the previous plot, but with the la_homes10 dataset
ggplot(la_homes10, aes(bed, bath)) +
  geom_jitter(width = 0.4, height = 0.05)
```

Most of the points are towards the bottom left of the plot.

Draw the same jittered scatter plot again, this time applying square-root transformations to the x and y scales.

```{r, sqrtsqrt}
# Draw the previous plot but with sqrt-sqrt scales

```

Refine the plot one more time, by making the points transparent.

Draw the previous plot again, setting the transparency level to 0.25 (and using a black and white theme).

```{r, transparency}
# Draw the previous plot but with transparency 0.25

```


# Chapter 3: Too many variables - correlation heatmaps

Here you'll look at a dataset on Scotch whisky preferences.

## Learning objectives

- Can draw a correlation heatmap.
- Can use hierarchical clustering to order cells in a correlation heatmap.
- Can adjust the color scale in a correlation heatmap.
- Can interpret a correlation heatmap.

## Loading the packages

You'll need `fst`, `dplyr`, `ggplot2`, and `ggcorrplot`. Just run this code.

```{r, load_pkg3, message = FALSE}
library(fst, lib.loc = rlib)
library(tibble)
library(ggplot2)
library(ggcorrplot, lib.loc = rlib)
```

## Get the dataset

The dataset is a modified version of `bayesm::Scotch`. 

- See https://www.rdocumentation.org/packages/bayesm/topics/Scotch for details.
- Each observation is a survey response indicating the brands of Scotch consumed in the last year.

Run this to download the data file.

```{r, download_scotch}
download.file(
  "https://github.com/datacamp/Visualizing-Big-Data-in-R-live-training/raw/master/data/scotch.fst",
  "scotch.fst"
)
```

Import the dataset from `scotch.fst` and assign to `scotch`.

```{r, explore_scotch}
# Import from scotch.fst
scotch <- 

# Explore the dataset, however you wish

```

## Draw a basic correlation heatmap

Calculate the correlation matrix for `scotch`, assigning to `correl`.

```{r, correl}
# Calculate the correlation matrix
correl <- 
```

Draw a correlation heatmap of it (no customization).

```{r, basic_heatmap}
# Draw a correlation heatmap

```

## Drop redundant cells

Draw the previous plot again, this time only showing the upper triangular portion of the correlation matrix.

```{r, upper}
# Draw a correlation heatmap of the upper triangular portion

```

## Use hierarchical clustering

Draw the previous plot again, this time using hierarchical clustering to reorder cells.

```{r, hierarchical}
# Draw a correlation heatmap of the upper triangular portion

```

# Override the color scale

Set the diagonal values in the correlation matrix to `NA`, then calculate the range of the correlation matrix.

```{r, range}
# Set the diagonals of correl to NA


# Calculate the range of correl (removing NAs)

```

We have both positive and negative correlations, so this is a slightly trickier situation than in the slides. We want a symmetric color scale centered on zero.

Define the limits of the color scale.

- Calculate the `max`imum `abs`olute correlation (removing NAs). Assign to `max_abs_correl`.
- Add some padding to `max_abs_correl` (any small number). Assign to `max_abs_correl_padded`.
- Define the scale limits as the vector (`-max_abs_correl_padded`, `max_abs_correl_padded`).

```{r, scale_limits}
# Calculate the largest absolute correlation (removing NAs)
max_abs_correl <-

# Add some padding
max_abs_correl_padded <- 

# Define limits from -max_abs_correl_padded to max_abs_correl_padded
scale_limits <- 
```

Draw the previous plot again, this time overriding the fill color scale.

- Add `scale_fill_gradient2()`.
- Pass the scale limits.
- Set the `high` argument to `"red"`.
- Set the `mid` argument to `"white"`.
- Set the `low` argument to `"blue"`.

```{r, color}
# Draw a correlation heatmap of the upper triangular portion
# Override the fill scale to use a 2-way gradient

```

## Interpreting correlation heatmaps

Drinkers of Glenfiddich are most likely to also drink which other whisky?

- [ ] Scoresby rare
- [ ] J & B
- [ ] Glenlivet
- [ ] Black & White
- [ ] Chivas Regal


Drinkers of Knockando are most likely to also drink which other whisky?

- [ ] Dewar's White Label
- [ ] Johnny Walker Red Label
- [ ] Johnny Walker Black Label
- [ ] Macallan
- [ ] Chivas Regal


# Chapter 4: Too many facets - trelliscope plots

Here, you'll explore the 30 stocks in the Dow Jones Industrial Average (DJIA).

## Learning objectives

- Can convert a ggplot into a trelliscope plot.
- Can use common arguments to control the appearance of a trelliscope plot.
- Can use the interactive filter and sort tools to interpret a trelliscope plot.

## Load the packages

You'll need `fst`, `tibble`, `ggplot2`, and `trelliscopejs`. Just run this code.

```{r, load_pkg4, message = FALSE}
library(fst, lib.loc = rlib)
library(tibble)
library(ggplot2)
library(trelliscopejs, lib.loc = rlib)
```

## Get the dataset

Run this to download the data file.

```{r, download_dow}
download.file(
  "https://github.com/datacamp/Visualizing-Big-Data-in-R-live-training/raw/master/data/dow_stock_prices.fst",
  "dow_stock_prices.fst"
)
```

Import the DJIA data from `dow_stock_prices.fst`, assigning to `dow_stock_prices`. Explore it however you wish.

```{r, explore_dow}
# Import the dataset from dow_stock_prices.fst
dow_stock_prices <- 

# Explore the dataset, however you wish

```

- `symbol`: The stock ticker symbol (unique ID for company).
- `company`: Human-readable company name.
- `sector`: Business sector that the company participates in.
- `date`: Date on which price and volume data was calculated for.
- `volume`: Number of shares traded on `date`.
- `adjusted`: Price of 1 share, after adjusting for dividends and splits.
- `relative`: Price of 1 share, relative to the maximum of `adjusted` over the time period
- `date_of_max_price`: For each stock, the date when the maximum share price was first achieved.
- `date_of_min_price`: For each stock, the date when the maximum share price was first achieved.

Take a look at the range of the dates in the dataset.

```{r, when}
# Get the range of the dates in dow_stock_prices

```

## From ggplot2 to trelliscopejs

Using `dow_stock_prices`, draw a line plot of `relative` versus `date`, faceted by `symbol` then `company`.

```{r, ggplot, fig.width = 10, fig.height = 8}
# Using dow_stock_prices, plot relative vs. date
# as a line plot
# faceted by symbol

```

Redraw the previous plot, this time as a trelliscope plot (no customization). 

- Set the `path` argument to `"rmarkdown_files/basic"`.

```{r, basic_trelliscope}
# Same plot as before, using trelliscope

```

# Improving the plot

We can improve on the previous plot by customizing it.

Redraw the previous plot, with the following changes.

- Set the `path` argument to `"rmarkdown_files/improved"`.
- Set the plot title to `Dow Jones Industrial Average`.
- Set the plot description to `Share prices 2017-01-01 to 2020-01-01`.
- Arrange the panels in `5` rows of `2` columns per page. 
- Increase the width of each panel to `1200` pixels.

```{r, improved}
# Draw the same plot again, customizing the display
# Set path, name, desc, nrow, ncol, width

```

## Labels

Add the `company` to the labels shown on each panel.

## Filtering

Which `sector` contains the most companies?

- [ ] Health Care
- [ ] Information Technology
- [ ] Consumer Staples
- [ ] Industrials
- [ ] Financials

Which `Energy` sector company began 2020 with a lower share price than 2017?

- [ ] CVX (Chevron)
- [ ] XOM (Exxon Mobil)

How many companies had a maximum price more than double the minimum price during the time period? That is, how many companies had a relative minimum less than `0.5`?

- [ ] 4
- [ ] 5
- [ ] 6
- [ ] 7

# Sorting

Based on mean daily volume of trades, which company was the 3rd most traded during the time period?

- [ ] AAPL (Apple)
- [ ] MSFT (Microsoft)
- [ ] CSCO (Cisco Systems)
- [ ] PFE (Pfizer)
- [ ] INTC (Intel)

Which company's median realtive price during the time period was lowest?

- [ ] AAPL (Apple)
- [ ] MSFT (Microsoft)
- [ ] V (Verizon Communications)
- [ ] MRK (Merck & Co.)
- [ ] PG ()

## Free scales

The relative share prices were plotted to make it easier to compare performance between companies. If you want to plot the non-normalized `adjusted` prices, you need to give each panel its own y-axis.

Redraw the previous plot, with these changes.

- Set the `path` argument to `"rmarkdown_files/yscale"`.
- On the y-axis, plot `adjusted` rather than `relative`.
- Give each panel a free y-axis scale (while keeping the x-axis scales the same).

```{r, yscale}
# This time plot adjusted vs. date
# Use a free y-scale

```

Which company, at it's maximum, had the highest price for 1 share?

- [ ] BA (Boeing)
- [ ] GS (Goldman Sachs Group)
- [ ] UNH (UnitedHealth Group)
- [ ] AAPL (Apple)
- [ ] MMM (3M)

## Interactive plotting with plotly

By using plotly to create each panel, each panel becomes interactive. Hover over the line to see the values of individual points.

Redraw the previous plot, using plotly to create the panels.

- Set the `path` argument to `"rmarkdown_files/plotly"`.

```{r, plotly}
# Redraw the last plot using plotly for panels

```

`V` (Verizon) had a dip in its share price in December 2018. What was its adjusted share price on 2018-12-24?

> 

