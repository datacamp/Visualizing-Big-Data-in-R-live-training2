---
title: "Visualizing Big Data in R (Answers)"
author: "Richie Cotton"
output: 
  html_document:
    self_contained: false
    lib_dir: trelliscope
---

# Prelude

Install these additional R packages.

```{r, install_pkgs, echo = FALSE, result = "hide"}
rlib <- "~/lib"
dir.create(rlib)
.libPaths(rlib)
library(remotes)
install_version("hexbin", "1.28.1", lib = rlib, upgrade = "never")
install_version("fst", "0.9.2", lib = rlib, upgrade = "never")
install_version("ggcorrplot", "0.1.3", lib = rlib, upgrade = "never")
install_version("trelliscopejs", "0.2.5", lib = rlib, upgrade = "never")
install_version("plotly", "4.9.2.1", lib = rlib, upgrade = "never")
```

# Chapter 1: Too many points - point size, transparency, transformations


Here, you'll look at the LA home prices dataset to explore ways of reducing overplotting.

## Learning objectives

- Understands that one cause of overplotting in scatter plots is simply that there are too many points.
- Can apply point size adjustments, transparency, and axis scale transformations to reduce overplotting problems.
- Can draw and interpret a hex plot.

## Loading the packages

You need a way to import a CSV file, `tibble` and `ggplot2`.

```{r, load_pkg1, message = FALSE}
# Load tibble, ggplot2, and a CSV reader
library(readr) # or library(data.table)
library(tibble)
library(ggplot2)
```

## Exploring the dataset

The dataset is here. Run this chunk!

```{r, data_file1}
data_file <- "../data/LAhomes.csv"
```

Read in the dataset from `data_file`, assigning the result to `la_homes`. Explore it (using whichever functions you like).

```{r, import}
# Read data_file from CSV
la_homes <- read_csv(data_file)

# Explore it
glimpse(la_homes)
```

- `price` is the sale price of the home, in USD.
- `sqft` is the area of the home in square feet (about 0.1 square meters).

Using `la_homes`, draw a scatter plot of `price` versus `sqft`.

```{r, basic_scatter}
# Using la_homes, plot price vs. sqft with point layer
ggplot(la_homes, aes(sqft, price)) +
  geom_point()
```

## Changing point size

Notice that points in the plot are heavily overplotted in the bottom left corner.

Redraw the basic scatter plot, changing the point size to `0.5`.

```{r, smaller_points}
# Draw same scatter plot, with size 0.5
ggplot(la_homes, aes(sqft, price)) +
  geom_point(size = 0.5)
```

Redraw the basic scatter plot, changing the point shape to be "pixel points".

```{r, pixel_points}
# Draw same scatter plot, with pixel shape
ggplot(la_homes, aes(sqft, price)) +
  geom_point(shape = ".")
```

## Using transparency

Redraw the basic scatter plot, changing the transparency level of points to `0.25`. Set a white background by using ggplot2's black and white theme.

```{r, transparency}
# Draw same scatter plot, with transparency 0.25 and black & white theme
ggplot(la_homes, aes(sqft, price)) +
  geom_point(alpha = 0.25) +
  theme_bw()
```

## Transform the axes

Most of the plots are stuck in the bottom-left corner. Transform the x and y axes to spread points more evenly throughout.

Redraw the basic scatter plot, applying a log10 transformation to the x and y scales.

```{r, loglog}
# Draw same scatter plot, with log-log scales
ggplot(la_homes, aes(sqft, price)) +
  geom_point() +
  scale_x_log10() +
  scale_y_log10()
```

Redraw the scatter plot using all three tricks at once.

- Set the point size to `0.5`.
- Set the point transparency to `0.25`.
- Using log10 transformations for the x and y scales.
- Use the black and white theme.

```{r, all_tricks}
# Draw same scatter plot, with all 3 tricks
ggplot(la_homes, aes(sqft, price)) +
  geom_point(size = 0.5, alpha = 0.25) +
  scale_x_log10() +
  scale_y_log10() +
  theme_bw()
```

## Hex plots

Draw a hex plot of `price` versus `sqft`.

```{r, hex}
# Using la_homes, plot price vs. sqft with hex layer
ggplot(la_homes, aes(sqft, price)) +
  geom_hex()
```

Redraw the hex plot, applying log10 transformations to the x and y scales.

```{r, hex_loglog}
# Draw same hex plot, with log-log scales
ggplot(la_homes, aes(sqft, price)) +
  geom_hex() +
  scale_x_log10() +
  scale_y_log10()
```

Which statement about the trend is true?

- [ ] Price increases roughly linearly with area.
- [ ] Price increases roughly linearly with log area.
- [ ] Log price increases roughly linearly with area.
- [x] Log price increases roughly linearly with log area.

Which statement about the overplotting is true?

- [ ] The majority of the houses are found in the region of darkest blues on the hex plot.
- [x] The majority of the houses are found in the region of lightest blues on the hex plot.
- [ ] The hex plot tells us nothing about where the majority of the houses are found.

# Chapter 2: Aligned values - jittering


Here you'll take another look at overplotting in the LA homes dataset.

## Learning objectives

- Understands that one cause of overplotting in scatter plots is low-precision, integer, or categorical variables taking exactly the same values.
- Can apply jittering, transparency, and scale transformations to solve the problem.

## Loading the packages

You'll need `readr`, `dplyr` and `ggplot2`. Just run this code.

```{r, load_pkg2, message = FALSE}
library(readr)
library(dplyr)
library(ggplot2)
```

## Importing and exploring the data

The dataset is here. Run this chunk!

```{r, data_file2}
data_file <- "../data/LAhomes.csv"
```

Import the LA homes dataset from `data_file`, assigning to `la_homes`.

```{r, import_la_homes2}
# Import data_file
la_homes <- read_csv(data_file)
```

- `bed` contains the number of bedrooms in the home.

Take a look at the distinct values in `bed` using `distinct()`.

```{r, beds}
# Look at the distinct values of the bath column
la_homes %>% 
  distinct(bed)
```

Notice that the number of bedrooms is always an integer and sometimes zero.

## Scatter plots of price vs. bedrooms

Using `la_homes`, draw a scatter plot of `price` versus `bed`.

```{r, price_vs_beds}
# Using la_homes, plot price vs. bed with a point layer
ggplot(la_homes, aes(bed, price)) +
  geom_point()
```

# Chapter 3: Too many variables - correlation heatmaps


Here you'll look at a dataset on Scotch whisky preferences.

## Learning objectives

- Can draw a correlation heatmap.
- Can use hierarchical clustering to order cells in a correlation heatmap.
- Can adjust the color scale in a correlation heatmap.
- Can interpret a correlation heatmap.

## Loading the packages

You'll need `fst`, `dplyr`, `ggplot2`, and `ggcorrplot`. Just run this code.

```{r, load_pkg3, message = FALSE}
library(fst, lib.loc = rlib)
library(tibble)
library(ggplot2)
library(ggcorrplot, lib.loc = rlib)
```

## Get the dataset

The dataset is a modified version of `bayesm::Scotch`. 

- See https://www.rdocumentation.org/packages/bayesm/topics/Scotch for details.
- Each observation is a survey response indicating the brands of Scotch consumed in the last year.

Run this to download the data file.

```{r, download_scotch}
download.file(
  "https://github.com/datacamp/Visualizing-Big-Data-in-R-live-training/raw/master/data/scotch.fst",
  "scotch.fst"
)
```

Import the dataset from `scotch.fst` and assign to `scotch`.

```{r, explore_scotch}
# Import from scotch.fst
scotch <- read_fst("scotch.fst")

# Explore the dataset, however you wish
glimpse(scotch)
```

## Draw a basic correlation heatmap

Calculate the correlation matrix for `scotch`, assigning to `correl`.

```{r, correl}
# Calculate the correlation matrix
correl <- cor(scotch)
```

Draw a correlation heatmap of it (no customization).

```{r, basic_heatmap}
# Draw a correlation heatmap
ggcorrplot(correl)
```

## Drop redundant cells

Draw the previous plot again, this time only showing the upper triangular portion of the correlation matrix.

```{r, upper}
# Draw a correlation heatmap of the upper triangular portion
ggcorrplot(correl, type = "upper")
```

## Use hierarchical clustering

Draw the previous plot again, this time using hierarchical clustering to reorder cells.

```{r, hierarchical}
# Draw a correlation heatmap of the upper triangular portion
ggcorrplot(correl, type = "upper", hc.order = TRUE)
```

# Override the color scale

Set the diagonal values in the correlation matrix to `NA`, then calculate the range of the correlation matrix.

```{r, range}
# Set the diagonals of correl to NA
diag(correl) <- NA

# Calculate the range of correl (removing NAs)
range(correl, na.rm = TRUE)
```

We have both positive and negative correlations, so this is a slightly trickier situation than in the slides. We want a symmetric color scale centered on zero.

Define the limits of the color scale.

- Calculate the `max`imum `abs`olute correlation (removing NAs). Assign to `max_abs_correl`.
- Add some padding to `max_abs_correl` (any small number). Assign to `max_abs_correl_padded`.
- Define the scale limits as the vector (`-max_abs_correl_padded`, `max_abs_correl_padded`).

```{r, scale_limits}
# Calculate the largest absolute correlation (removing NAs)
max_abs_correl <- max(abs(correl), na.rm = TRUE)

# Add some padding
max_abs_correl_padded <- max_abs_correl + 0.02

# Define limits from -max_abs_correl_padded to max_abs_correl_padded
scale_limits <- c(-max_abs_correl_padded, max_abs_correl_padded)
```

Draw the previous plot again, this time overriding the fill color scale.

- Add `scale_fill_gradient2()`.
- Pass the scale limits.
- Set the `high` argument to `"red"`.
- Set the `mid` argument to `"white"`.
- Set the `low` argument to `"blue"`.

```{r, color}
# Draw a correlation heatmap of the upper triangular portion
# Override the fill scale to use a 2-way gradient
ggcorrplot(correl, type = "upper", hc.order = TRUE) +
  scale_fill_gradient2(
    limits = scale_limits,
    high = "red",
    mid = "white",
    low = "blue"
  )
```

## Interpreting correlation heatmaps

Drinkers of Glenfiddich are most likely to also drink which other whisky?

- [ ] Scoresby rare
- [ ] J & B
- [x] Glenlivet
- [ ] Black & White
- [ ] Chivas Regal


Drinkers of Knockando are most likely to also drink which other whisky?

- [ ] Dewar's White Label
- [ ] Johnny Walker Red Label
- [ ] Johnny Walker Black Label
- [x] Macallan
- [ ] Chivas Regal

# Chapter 4: Too many facets - trelliscope plots

Here, you'll explore the 30 stocks in the Dow Jones Industrial Average (DJIA).

## Learning objectives

- Can convert a ggplot into a trelliscope plot.
- Can use common arguments to control the appearance of a trelliscope plot.
- Can use the interactive filter and sort tools to interpret a trelliscope plot.

## Load the packages

You'll need `fst`, `tibble`, `ggplot2`, and `trelliscopejs`. Just run this code.

```{r, load_pkg4, message = FALSE}
library(fst, lib.loc = rlib)
library(tibble)
library(ggplot2)
library(trelliscopejs, lib.loc = rlib)
```

## Get the dataset

Run this to download the data file.

```{r, download_dow}
download.file(
  "https://github.com/datacamp/Visualizing-Big-Data-in-R-live-training/raw/master/data/dow_stock_prices.fst",
  "dow_stock_prices.fst"
)
```

Import the DJIA data from `dow_stock_prices.fst`, assigning to `dow_stock_prices`. Explore it however you wish.

```{r, explore_dow}
# Import the dataset from dow_stock_prices.fst
dow_stock_prices <- read_fst("dow_stock_prices.fst")

# Explore the dataset, however you wish
glimpse(dow_stock_prices)
```

- `symbol`: The stock ticker symbol (unique ID for company).
- `company`: Human-readable company name.
- `sector`: Business sector that the company participates in.
- `date`: Date on which price and volume data was calculated for.
- `volume`: Number of shares traded on `date`.
- `adjusted`: Price of 1 share, after adjusting for dividends and splits.
- `relative`: Price of 1 share, relative to the maximum of `adjusted` over the time period
- `date_of_max_price`: For each stock, the date when the maximum share price was first achieved.
- `date_of_min_price`: For each stock, the date when the maximum share price was first achieved.

Take a look at the range of the dates in the dataset.

```{r, when}
# Get the range of the dates in dow_stock_prices
range(dow_stock_prices$date)
```

## From ggplot2 to trelliscopejs

Using `dow_stock_prices`, draw a line plot of `relative` versus `date`, faceted by `symbol`.

```{r, ggplot, fig.width = 10, fig.height = 8}
# Using dow_stock_prices, plot relative vs. date
# as a line plot
# faceted by symbol
ggplot(dow_stock_prices, aes(date, relative)) +
  geom_line() +
  facet_wrap(vars(symbol))
```

Redraw the previous plot, this time as a trelliscope plot (no customization). 

- Set the `path` argument to `"trelliscope/basic"`.

```{r, basic_trelliscope}
# Same plot as before, using trelliscope
ggplot(dow_stock_prices, aes(date, relative)) +
  geom_line() +
  facet_trelliscope(
    vars(symbol), 
    path = "trelliscope/basic"
  )
```

# Improving the plot

We can improve on the previous plot by customizing it.

Redraw the previous plot, with the following changes.

- Set the `path` argument to `"trelliscope/improved"`.
- Set the plot title to `Dow Jones Industrial Average`.
- Set the plot description to `Share prices 2017-01-01 to 2020-01-01`.
- Arrange the panels in `5` rows of `2` columns per page. 
- Increase the width of each panel to `1200` pixels.

```{r, improved}
# Draw the same plot again, customizing the display
# Set path, name, desc, nrow, ncol, width
ggplot(dow_stock_prices, aes(date, relative)) +
  geom_line() +
  facet_trelliscope(
    vars(symbol),
    path = "trelliscope/improved",
    name = "Dow Jones Industrial Average",
    desc = "Share prices 2017-01-01 to 2020-01-01",
    nrow = 5, 
    ncol = 2,
    width = 1200
  )
```

## Labels

Add the `company` to the labels shown on each panel.

## Filtering

Which `sector` contains the most companies?

- [ ] Health Care
- [x] Information Technology
- [ ] Consumer Staples
- [ ] Industrials
- [ ] Financials

Which `Energy` sector company began 2020 with a lower share price than 2017?

- [ ] CVX (Chevron)
- [x] XOM (Exxon Mobil)

How many companies had a maximum price more than double the minimum price during the time period? That is, how many companies had a relative minimum less than `0.5`?

- [ ] 4
- [ ] 5
- [x] 6
- [ ] 7

# Sorting

Based on mean daily volume of trades, which company was the 3rd most traded during the time period?

- [ ] AAPL (Apple)
- [ ] MSFT (Microsoft)
- [ ] CSCO (Cisco Systems)
- [ ] PFE (Pfizer)
- [x] INTC (Intel)

Which company's median realtive price during the time period was lowest?

- [x] AAPL (Apple)
- [ ] MSFT (Microsoft)
- [ ] V (Verizon Communications)
- [ ] MRK (Merck & Co.)
- [ ] PG ()

## Free scales

The relative share prices were plotted to make it easier to compare performance between companies. If you want to plot the non-normalized `adjusted` prices, you need to give each panel its own y-axis.

Redraw the previous plot, with these changes.

- Set the `path` argument to `"trelliscope/yscale"`.
- On the y-axis, plot `adjusted` rather than `relative`.
- Give each panel a free y-axis scale (while keeping the x-axis scales the same).

```{r, yscale}
# This time plot adjusted vs. date
# Use a free y-scale
ggplot(dow_stock_prices, aes(date, adjusted)) +
  geom_line() +
  facet_trelliscope(
    vars(symbol),
    path = "trelliscope/yscale",
    name = "Dow Jones Industrial Average",
    desc = "Share prices 2017-01-01 to 2020-01-01",
    nrow = 5, 
    ncol = 2,
    width = 1200,
    scales = c("same", "free")
  )
```

Which company, at it's maximum, had the highest price for 1 share?

- [x] BA (Boeing)
- [ ] GS (Goldman Sachs Group)
- [ ] UNH (UnitedHealth Group)
- [ ] AAPL (Apple)
- [ ] MMM (3M)

## Interactive plotting with plotly

By using plotly to create each panel, each panel becomes interactive. Hover over the line to see the values of individual points.

Redraw the previous plot, using plotly to create the panels.

- Set the `path` argument to `"trelliscope/plotly"`.

```{r, plotly}
# Redraw the last plot using plotly for panels
ggplot(dow_stock_prices, aes(date, adjusted)) +
  geom_line() +
  facet_trelliscope(
    vars(symbol),
    path = "trelliscope/plotly",
    name = "Dow Jones Industrial Average",
    desc = "Share prices 2017-01-01 to 2020-01-01",
    nrow = 5, 
    ncol = 2,
    width = 1200,
    scales = c("same", "free"),
    as_plotly = TRUE
  )
```

`V` (Verizon) had a dip in its share price in December 2018. What was its adjusted share price on 2018-12-24?

> 120.78
